{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import psycopg2\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from Joe_prepCommentForTraining import prepCommentForTraining \n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "from credentials import credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fit_and_predict import fit_make_crosstab, get_model\n",
    "from env_utils import get_working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_working_dir('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the twitter oauth details:\n",
    "conn = psycopg2.connect(\n",
    "        host=credentials['host'],\n",
    "        port = credentials['port'],\n",
    "        database=credentials['database'],\n",
    "        user=credentials['user'],\n",
    "        password=credentials['password'],\n",
    ")\n",
    "# Create a cursor object\n",
    "    \n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify principles 1-5*\n",
    "\n",
    "#### Import the binary trainingData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQLCommand = (\"\"\"\n",
    "\n",
    "    SELECT source, \n",
    "           commentID,\n",
    "           cleanedComment,\n",
    "           recommend,\n",
    "           CASE\n",
    "              WHEN fastAccess >= 1 THEN 1\n",
    "              ELSE 0\n",
    "           END AS fastAccess,\n",
    "           CASE\n",
    "              WHEN effTreat >= 1 THEN 1\n",
    "              ELSE 0\n",
    "           END AS effTreat,\n",
    "           CASE\n",
    "              WHEN emotSup >= 1 THEN 1\n",
    "              ELSE 0\n",
    "           END AS emotSup,\n",
    "           CASE\n",
    "              WHEN apen >= 1 THEN 1\n",
    "              ELSE 0\n",
    "           END AS apen\n",
    "      FROM trainingData\n",
    "     WHERE fastAccess IS NOT NULL\n",
    "       AND effTreat IS NOT NULL\n",
    "       AND emotSup IS NOT NULL\n",
    "       AND apen IS NOT NULL\n",
    "       AND source != 'miscTweets'\n",
    "       AND cleanedComment IS NOT NULL\n",
    "       AND cleanedComment != ''\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(SQLCommand)\n",
    "df = pd.DataFrame(cursor.fetchall())\n",
    "df.columns = ['source','commentID','cleanedComment','recommend','fastAccess','effTreat','emotSup','apen']\n",
    "\n",
    "df = df[~((df['source'] == 'twitter') & (df['recommend'] == 0))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the comments for modelling and train the fastAccess model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n",
      "case set to lower\n",
      "+ replaced with &\n",
      "forward slashes replaced with space\n",
      "u200ef etc removed\n",
      "a & e correct to a&e\n",
      "a&e changed to ae to deal with tokenizing nightmare!\n",
      "non-standard characters removed\n",
      "2 newly empty/blank comments removed from trainingData\n",
      "trainProportion = math.ceil(len(df)*training_proportion)\n",
      "Generating new word2index model\n",
      "\n",
      "maxlen in training data: 2540\n",
      "maxlen set to: 2540\n",
      "word2index = collections.defaultdict(int)\n",
      "for wid, word in enumerate(counter.most_common(VOCAB_SIZE)):\n",
      "                    word2index[word[0]] = wid + 1\n",
      "                #vocab_sz = len(word2index) + 1\n",
      "                index2word = {v:k for k, v in word2index.items()}\n",
      "word2index_Name: 20210105 trainingData PRINCIPLES_PROB word2index maxLen 2540.pickle\n",
      "\n",
      "word2index pickle dumped, name: 20210105 trainingData PRINCIPLES_PROB word2index maxLen 2540.pickle\n",
      "index2word_Name: 20210105 trainingData index2word maxLen 2540.pickle\n",
      "X number sorted\n",
      "Y number sorted\n",
      "20210105fastAccess ALL PRINCIPLE_PROB CNN v5000 em100128 w3 b256 ep1 using 20210105 trainingData PRINCIPLES_PROB word2index maxLen 2540.pickle.hdf5\n",
      "28/28 [==============================] - 29s 1s/step - loss: 0.6316 - accuracy: 0.6620 - val_loss: 0.5354 - val_accuracy: 0.7446\n",
      "    source                          commentID                                     cleanedComment  \\\n",
      "0  twitter             1197099171196678144RJ2  Always so appreciative of the volunteers at th...   \n",
      "1  twitter           1157567510008467457RHQHH  Sincere thanks to Mr Watson and his team and a...   \n",
      "2  twitter             1206863344185085952RHQ  Day4 of #chemo at @SheffieldHosp #nursing has ...   \n",
      "3  twitter         972051755105218562@sthknhs  Yeay Remission continues. #hodgkins Great expe...   \n",
      "4  twitter  1031493628735176705@WorcsAcuteNHS  #Mondaymotivation 9 years #lymphoma remission ...   \n",
      "\n",
      "   recommend  actual  effTreat  emotSup  apen                                            comment  \\\n",
      "0        5.0       1         1        1     0  always so appreciative of the volunteers at th...   \n",
      "1        5.0       0         1        1     0  sincere thanks to mr watson and his team and a...   \n",
      "2        5.0       0         1        0     0  day of #chemo at @sheffieldhosp #nursing has b...   \n",
      "3        5.0       0         1        0     0  yeay remission continues. #hodgkins great expe...   \n",
      "4        5.0       0         1        0     0  #mondaymotivation  years #lymphoma remission t...   \n",
      "\n",
      "      probN     probY  \n",
      "0  0.669835  0.330165  \n",
      "1  0.704643  0.295357  \n",
      "2  0.687395  0.312605  \n",
      "3  0.714036  0.285964  \n",
      "4  0.738512  0.261488  \n",
      "\n",
      "Cross-tab for validation data (actual coding reads across, predictions downwards)\n",
      "* accuracy = 76.68% *\n",
      "            len    \n",
      "predicted     n   y\n",
      "actual             \n",
      "n          1291  12\n",
      "y           396  51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe\\PEP Health\\Tech - Tech\\Scripts\\Python\\run-model\\fit_and_predict.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['predicted'][results['probY'] >= probY_threshold] = 'y'\n",
      "C:\\Users\\Joe\\PEP Health\\Tech - Tech\\Scripts\\Python\\run-model\\fit_and_predict.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['actual'][results['actual'] == 0] = 'n'\n"
     ]
    }
   ],
   "source": [
    "prepped_data = prepCommentForTraining(df, 'cleanedComment', 'comment', 'fastAccess', \n",
    "                                      'binary', 2540, 5000, 0.8, 'None', 'PRINCIPLES_PROB')\n",
    "Params = collections.namedtuple('Params',[\"vocab_size\", \"embed_size\", \"n_filters\", \n",
    "                              \"n_words\", \"batch_size\", \"n_epochs\"])\n",
    "params = Params(5000, 100, 128, 3, 256, 1)\n",
    "model = get_model(prepped_data.maxlen, params)\n",
    "domain = 'fastAccess'\n",
    "probY_threshold = 0.4\n",
    "\n",
    "# Above params reduced for speed. Original values:\n",
    "# params = Params(5000, 100, 256, 3, 256, 50)\n",
    "\n",
    "fit_make_crosstab(prepped_data, model, params, domain, probY_threshold);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
