{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import psycopg2\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from utils_prep_comment_for_training import prepCommentForTraining \n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "from credentials import credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_fit_and_predict import fit_make_crosstab, get_model\n",
    "from utils_env import get_working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_working_dir('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the twitter oauth details:\n",
    "conn = psycopg2.connect(\n",
    "        host=credentials['host'],\n",
    "        port = credentials['port'],\n",
    "        database=credentials['database'],\n",
    "        user=credentials['user'],\n",
    "        password=credentials['password'],\n",
    ")\n",
    "# Create a cursor object\n",
    "    \n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify principles 1-5*\n",
    "\n",
    "#### Import the binary trainingData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQLCommand = (\"\"\"\n",
    "\n",
    "    SELECT source, \n",
    "           commentID,\n",
    "           cleanedComment,\n",
    "           recommend,\n",
    "           CASE\n",
    "              WHEN fastAccess >= 1 THEN 1\n",
    "              ELSE 0\n",
    "           END AS fastAccess,\n",
    "           CASE\n",
    "              WHEN effTreat >= 1 THEN 1\n",
    "              ELSE 0\n",
    "           END AS effTreat,\n",
    "           CASE\n",
    "              WHEN emotSup >= 1 THEN 1\n",
    "              ELSE 0\n",
    "           END AS emotSup,\n",
    "           CASE\n",
    "              WHEN apen >= 1 THEN 1\n",
    "              ELSE 0\n",
    "           END AS apen\n",
    "      FROM trainingData\n",
    "     WHERE fastAccess IS NOT NULL\n",
    "       AND effTreat IS NOT NULL\n",
    "       AND emotSup IS NOT NULL\n",
    "       AND apen IS NOT NULL\n",
    "       AND source != 'miscTweets'\n",
    "       AND cleanedComment IS NOT NULL\n",
    "       AND cleanedComment != ''\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(SQLCommand)\n",
    "df = pd.DataFrame(cursor.fetchall())\n",
    "df.columns = ['source','commentID','cleanedComment','recommend','fastAccess','effTreat','emotSup','apen']\n",
    "\n",
    "df = df[~((df['source'] == 'twitter') & (df['recommend'] == 0))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the comments for modelling and train the fastAccess model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n",
      "case set to lower\n",
      "+ replaced with &\n",
      "forward slashes replaced with space\n",
      "u200ef etc removed\n",
      "a & e correct to a&e\n",
      "a&e changed to ae to deal with tokenizing nightmare!\n",
      "non-standard characters removed\n",
      "2 newly empty/blank comments removed from trainingData\n",
      "trainProportion = math.ceil(len(df)*training_proportion)\n",
      "Generating new word2index model\n",
      "\n",
      "maxlen in training data: 2540\n",
      "maxlen set to: 2540\n",
      "word2index = collections.defaultdict(int)\n",
      "for wid, word in enumerate(counter.most_common(VOCAB_SIZE)):\n",
      "                    word2index[word[0]] = wid + 1\n",
      "                #vocab_sz = len(word2index) + 1\n",
      "                index2word = {v:k for k, v in word2index.items()}\n",
      "word2index_Name: 20210105 trainingData PRINCIPLES_PROB word2index maxLen 2540.pickle\n",
      "\n",
      "word2index pickle dumped, name: 20210105 trainingData PRINCIPLES_PROB word2index maxLen 2540.pickle\n",
      "index2word_Name: 20210105 trainingData index2word maxLen 2540.pickle\n",
      "X number sorted\n",
      "Y number sorted\n",
      "20210105fastAccess ALL PRINCIPLE_PROB CNN v5000 em100128 w3 b256 ep1 using 20210105 trainingData PRINCIPLES_PROB word2index maxLen 2540.pickle.hdf5\n",
      "28/28 [==============================] - 30s 1s/step - loss: 0.6390 - accuracy: 0.6247 - val_loss: 0.5287 - val_accuracy: 0.7440\n",
      "    source                          commentID                                     cleanedComment  \\\n",
      "0  twitter             1247542755259060224RTE  So proud of my mum ringing the bell for the en...   \n",
      "1  twitter  1037197389214507010@SheffieldHosp  Exactly 1 year ago today I awoke to this view....   \n",
      "2  twitter  1113858257649569794@gloshospitals  The only way to say thank you to my @gloshospi...   \n",
      "3  twitter   990874221768269824@gloshospitals  Ever grateful for the amazing fertility treatm...   \n",
      "4  twitter        985962801180102656@BSUH_NHS  After three days in intensive care - for the s...   \n",
      "\n",
      "   recommend  actual  effTreat  emotSup  apen                                            comment  \\\n",
      "0        5.0       0         1        0     0  so proud of my mum ringing the bell for the en...   \n",
      "1        4.0       0         1        0     0  exactly  year ago today i awoke to this view. ...   \n",
      "2        4.0       0         1        0     0  the only way to say thank you to my @gloshospi...   \n",
      "3        5.0       0         1        0     0  ever grateful for the amazing fertility treatm...   \n",
      "4        5.0       0         1        0     0  after three days in intensive care - for the s...   \n",
      "\n",
      "      probN     probY  \n",
      "0  0.764146  0.235854  \n",
      "1  0.785283  0.214717  \n",
      "2  0.780060  0.219940  \n",
      "3  0.752453  0.247547  \n",
      "4  0.687335  0.312665  \n",
      "\n",
      "Cross-tab for validation data (actual coding reads across, predictions downwards)\n",
      "* accuracy = 74.85% *\n",
      "              len     \n",
      "predicted       n    y\n",
      "actual                \n",
      "n          1302.0  NaN\n",
      "y           440.0  8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe\\PEP Health\\Tech - Tech\\Scripts\\Python\\run-model\\utils_fit_and_predict.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['predicted'][results['probY'] >= probY_threshold] = 'y'\n",
      "C:\\Users\\Joe\\PEP Health\\Tech - Tech\\Scripts\\Python\\run-model\\utils_fit_and_predict.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['actual'][results['actual'] == 0] = 'n'\n"
     ]
    }
   ],
   "source": [
    "prepped_data = prepCommentForTraining(df, 'cleanedComment', 'comment', 'fastAccess', \n",
    "                                      'binary', 2540, 5000, 0.8, 'None', 'PRINCIPLES_PROB')\n",
    "Params = collections.namedtuple('Params',[\"vocab_size\", \"embed_size\", \"n_filters\", \n",
    "                              \"n_words\", \"batch_size\", \"n_epochs\"])\n",
    "params = Params(5000, 100, 128, 3, 256, 1)\n",
    "model = get_model(prepped_data.maxlen, params)\n",
    "domain = 'fastAccess'\n",
    "probY_threshold = 0.4\n",
    "\n",
    "# Above params reduced for speed. Original values:\n",
    "# params = Params(5000, 100, 256, 3, 256, 50)\n",
    "\n",
    "fit_make_crosstab(prepped_data, model, params, domain, probY_threshold);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
